{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "# VGG16 was designed to work on 224 x 224 pixel input images sizes\n",
    "img_rows = 224\n",
    "img_cols = 224\n",
    "\n",
    "#Loads the VGG16 model \n",
    "model = VGG16(weights = 'imagenet', \n",
    "                 include_top = False, \n",
    "                 input_shape = (img_rows, img_cols, 3))\n",
    "\n",
    "# Here we freeze the last 4 layers \n",
    "# Layers are set to trainable as True by default\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer False\n",
      "1 Conv2D True\n",
      "2 Conv2D True\n",
      "3 MaxPooling2D True\n",
      "4 Conv2D True\n",
      "5 Conv2D True\n",
      "6 MaxPooling2D True\n",
      "7 Conv2D True\n",
      "8 Conv2D True\n",
      "9 Conv2D True\n",
      "10 MaxPooling2D True\n",
      "11 Conv2D True\n",
      "12 Conv2D True\n",
      "13 Conv2D True\n",
      "14 MaxPooling2D True\n",
      "15 Conv2D True\n",
      "16 Conv2D True\n",
      "17 Conv2D True\n",
      "18 MaxPooling2D True\n"
     ]
    }
   ],
   "source": [
    "# Let's print our layers \n",
    "for (i,layer) in enumerate(model.layers):\n",
    "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTopModel(bottom_model, num_classes):\n",
    "    \"\"\"creates the top or head of the model that will be \n",
    "    placed ontop of the bottom layers\"\"\"\n",
    "\n",
    "    top_model = bottom_model.output\n",
    "    top_model = GlobalAveragePooling2D()(top_model)\n",
    "    top_model = Dense(1024,activation='relu')(top_model)\n",
    "    top_model = Dense(512,activation='relu')(top_model)\n",
    "    top_model = Dense(248,activation='relu')(top_model)\n",
    "    top_model = Dense(num_classes,activation='softmax')(top_model)\n",
    "    return top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(None, 224, 224, 3) dtype=float32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x1bc33d8f348>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1bc3c607688>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1bc3c607748>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1bc3c66b688>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1bc3c66bd48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1bc3c6789c8>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1bc3c678648>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1bc3c67d488>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1bc3c688b08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1bc3c68c308>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1bc3c696688>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1bc3c69a408>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1bc3c699c08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1bc3c6aaac8>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1bc3c6afc88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1bc3c6b4788>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1bc3c6b9d88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1bc3c6c3e08>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1bc3c6c7c08>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 248)               127224    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 1245      \n",
      "=================================================================\n",
      "Total params: 15,893,269\n",
      "Trainable params: 15,893,269\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "num_classes = 5\n",
    "\n",
    "FC_Head = addTopModel(model, num_classes)\n",
    "\n",
    "modelnew = Model(inputs=model.input, outputs=FC_Head)\n",
    "\n",
    "print(modelnew.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 93 images belonging to 5 classes.\n",
      "Found 25 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_dir = 'C://Users//Rahul Prajapati//Desktop//mlops-ws//data//train'\n",
    "validation_data_dir = 'C://Users//Rahul Prajapati//Desktop//mlops-ws//data//val'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=20,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    " \n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "# Change the batchsize according to your system RAM\n",
    "train_batchsize = 15\n",
    "val_batchsize = 10\n",
    " \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=train_batchsize,\n",
    "        class_mode='categorical')\n",
    " \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=val_batchsize,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 115s 12s/step - loss: 0.6112 - accuracy: 0.7810 - val_loss: 0.5732 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.57317, saving model to face_vgg16.h5\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 137s 14s/step - loss: 0.5085 - accuracy: 0.8000 - val_loss: 0.4823 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.57317 to 0.48230, saving model to face_vgg16.h5\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 132s 13s/step - loss: 0.5016 - accuracy: 0.8000 - val_loss: 0.4794 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.48230 to 0.47936, saving model to face_vgg16.h5\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 155s 16s/step - loss: 0.5112 - accuracy: 0.8000 - val_loss: 0.5153 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.47936\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 133s 13s/step - loss: 0.5011 - accuracy: 0.8000 - val_loss: 0.4925 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.47936\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 144s 14s/step - loss: 0.5102 - accuracy: 0.8000 - val_loss: 0.4726 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.47936 to 0.47255, saving model to face_vgg16.h5\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 138s 14s/step - loss: 0.5033 - accuracy: 0.8000 - val_loss: 0.5133 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.47255\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 135s 14s/step - loss: 0.5002 - accuracy: 0.8000 - val_loss: 0.5021 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.47255\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 150s 15s/step - loss: 0.5035 - accuracy: 0.8000 - val_loss: 0.4728 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.47255\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint , EarlyStopping\n",
    "                   \n",
    "checkpoint = ModelCheckpoint(\"face_vgg16.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "earlystop = EarlyStopping(monitor=\"val_loss\",\n",
    "                             min_delta=0,\n",
    "                             patience=3,\n",
    "                             verbose=1,\n",
    "                           restore_best_weights=True)\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [ checkpoint, earlystop]\n",
    "\n",
    "# Note we use a very small learning rate \n",
    "modelnew.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = Adam(lr = 0.001),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "nb_train_samples = 91\n",
    "nb_validation_samples = 24\n",
    "epochs =10\n",
    "batch_size = 16\n",
    "\n",
    "history = modelnew.fit_generator(\n",
    "    train_generator,\n",
    "    epochs = epochs,\n",
    "    steps_per_epoch = 10,\n",
    "    callbacks = callbacks,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = nb_validation_samples // batch_size)\n",
    "\n",
    "modelnew.save(\"face_vgg16.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "classifier = load_model(\"face_vgg16.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "monkey_breeds_dict =  {\"[0]\": \"ben_afflek\", \n",
    "                        \"[1]\": \"elton_john\",\n",
    "                       \"[2]\": \"jerry_seinfeld\",\n",
    "                        \"[3]\": \"madonna\",\n",
    "                      \"[4]\": \"mindy_kaling\"}\n",
    "\n",
    "monkey_breeds_dict_n =  {\"ben_afflek\": \"ben_afflek\", \n",
    "                        \"elton_john\": \"elton_john\",\n",
    "                    \"jerry_seinfeld\":\"jerry_seinfeld\",\n",
    "                           \"madonna\":\"madonna\",\n",
    "                      \"mindy_kaling\":  \"mindy_kaling\" }\n",
    "\n",
    "def draw_test(name, pred, im):\n",
    "    monkey = monkey_breeds_dict[str(pred)]\n",
    "    BLACK = [0,0,0]\n",
    "    expanded_image = cv2.copyMakeBorder(im, 80, 0, 0, 100 ,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    cv2.putText(expanded_image, monkey, (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2)\n",
    "    cv2.imshow(name, expanded_image)\n",
    "\n",
    "def getRandomImage(path):\n",
    "    \"\"\"function loads a random images from a random folder in our test path \"\"\"\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "    random_directory = np.random.randint(0,len(folders))\n",
    "    path_class = folders[random_directory]\n",
    "    print(\"Class - \" + monkey_breeds_dict_n[str(path_class)])\n",
    "    file_path = path + path_class\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    return cv2.imread(file_path+\"/\"+image_name)    \n",
    "\n",
    "for i in range(0,10):\n",
    "    input_im = getRandomImage(\"C://Users//Rahul Prajapati//Desktop//mlops-ws//data/val/\")\n",
    "    input_original = input_im.copy()\n",
    "    input_original = cv2.resize(input_original, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_LINEAR)\n",
    "    \n",
    "    input_im = cv2.resize(input_im, (224, 224), interpolation = cv2.INTER_LINEAR)\n",
    "    input_im = input_im / 255.\n",
    "    input_im = input_im.reshape(1,224,224,3) \n",
    "    \n",
    "    # Get Prediction\n",
    "    res = np.argmax(classifier.predict(input_im, 1, verbose = 0), axis=1)\n",
    "    \n",
    "    # Show image with predicted class\n",
    "    draw_test(\"Prediction\", res, input_original) \n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
